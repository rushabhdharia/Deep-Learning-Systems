{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPool2D, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6265, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_tr7.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_te7.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Channel Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.expand_dims(test_data, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_model(ip_shape = [28, 28, 1], latent_dim = 4):\n",
    "    input_img = Input(ip_shape) \n",
    "    \n",
    "    encoder_model = Sequential()   \n",
    "    encoder_model.add(Conv2D(16, kernel_size = (5, 5), input_shape = ip_shape, activation = 'relu'))\n",
    "    encoder_model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "    encoder_model.add(Conv2D(64, kernel_size = (2, 2), activation = 'relu'))\n",
    "    encoder_model.add(Flatten())\n",
    "    encoder_model.add(Dense(128))\n",
    "    \n",
    "    encoder_output = encoder_model(input_img)\n",
    "    \n",
    "    z_mean = Dense(latent_dim)(encoder_output)\n",
    "    z_log_var = Dense(latent_dim)(encoder_output)\n",
    "     \n",
    "    epsilon =  K.random_normal(shape=K.shape(z_mean))\n",
    "    #reparameterize\n",
    "    z = z_mean + K.exp(0.5 + z_log_var) * epsilon\n",
    "    \n",
    "    decoder_model = Sequential()\n",
    "    decoder_model.add(Dense(latent_dim*2, input_shape = z.get_shape(), activation = 'relu'))\n",
    "    decoder_model.add(Dense(28*28, activation = 'relu'))\n",
    "    decoder_model.add(Reshape(target_shape = (28,28, 1)))\n",
    "    decoder_model.add(Conv2DTranspose(64, kernel_size = (2, 2), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(32, kernel_size = (3, 3), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(16, kernel_size = (5, 5), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(1, kernel_size = (5, 5), padding='SAME'))\n",
    "    \n",
    "    prediction = decoder_model(z)\n",
    "      \n",
    "    vae_model = Model(inputs = input_img, outputs = prediction)\n",
    "    \n",
    "    return vae_model, z_mean, z_log_var, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(ip, op):\n",
    "    kld = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    kld = kld / ( 28 * 28 )\n",
    "    bce = tf.losses.sigmoid_cross_entropy(ip, op)\n",
    "    \n",
    "    return bce+kld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rushabh/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/rushabh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/rushabh/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "vae_model, z_mean, z_log_var, decoder_model = VAE_model() \n",
    "vae_model.compile(loss=vae_loss,optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6265 samples, validate on 1028 samples\n",
      "Epoch 1/50\n",
      "6265/6265 [==============================] - 31s 5ms/sample - loss: 0.3265 - val_loss: 0.2396\n",
      "Epoch 2/50\n",
      "6265/6265 [==============================] - 27s 4ms/sample - loss: 0.2029 - val_loss: 0.1746\n",
      "Epoch 3/50\n",
      "4736/6265 [=====================>........] - ETA: 6s - loss: 0.1690"
     ]
    }
   ],
   "source": [
    "vae_model.fit(train_data, train_data, batch_size=64, epochs=50, shuffle = True, validation_data = (test_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.save_weights('./keras_checkpoints/vae.cpkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model = model.load_weights('./keras_checkpoints/vae.cpkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://www.tensorflow.org/tutorials/generative/cvae\n",
    "2. https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "\n",
    "test_original = test_data[np.random.choice(test_data.shape[0], 5)]\n",
    "\n",
    "test_recon = vae_model.predict(test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "  plt.figure(figsize=(5, 10))\n",
    "  \n",
    "  ax = plt.subplot(1, 2, 1)\n",
    "  plt.imshow(test_original[i].reshape([28, 28]))\n",
    "  ax.set_xticklabels([])\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  \n",
    "  ax = plt.subplot(1, 2, 2)\n",
    "  plt.imshow(test_recon[i].reshape([28, 28]))\n",
    "  ax.set_xticklabels([])\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vector = vae_model.predict(train_data[0], output = vae_model.get_layer(index=11).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=vae_model.input, outputs=vae_model.get_layer(index = 11).output)\n",
    "intermediate_output = intermediate_layer_model.predict(np.expand_dims(test_original[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img = intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images):\n",
    "  n = len(images)\n",
    "  plt.figure(figsize=(20, 20 * n))\n",
    "  for i in range(n):\n",
    "      ax = plt.subplot(1, n, i + 1)\n",
    "      plt.imshow(images[i])\n",
    "      ax.set_xticklabels([])\n",
    "      ax.set_yticklabels([])\n",
    "      ax.set_xticks([])\n",
    "      ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tweaked_images = 10\n",
    "for dim in range(4):\n",
    "  tweaked_vectors = []\n",
    "  for new_val in np.linspace(-2, 2, num_tweaked_images):\n",
    "    tweaked_vec = ref_img.copy()\n",
    "    tweaked_vec[0, dim] = new_val\n",
    "    tweaked_vectors.append(tweaked_vec)\n",
    "  gen_images = decoder_model.predict(np.array(tweaked_vectors))  \n",
    "#   gen_images = sess.run(generate_image, feed_dict={Z: np.array(tweaked_vectors)})\n",
    "  plot_images(gen_images.reshape([-1, 28, 28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
