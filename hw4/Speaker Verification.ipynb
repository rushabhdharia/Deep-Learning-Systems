{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CVMyaKTbfnDe"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations, product\n",
    "\n",
    "import pickle\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eKiP2vAsf2cC",
    "outputId": "c9509773-ba6c-4e2d-c899-98a936222f71"
   },
   "outputs": [],
   "source": [
    "with open('hw4_trs.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ERjzc8ZPf-iL",
    "outputId": "c0eaccb2-2591-42b8-b9a2-046bad9577dc"
   },
   "outputs": [],
   "source": [
    "with open('hw4_tes.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V879fkbMgAEG"
   },
   "outputs": [],
   "source": [
    "train_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QcgCEbpogBs6"
   },
   "outputs": [],
   "source": [
    "test_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R-5czByMgES8"
   },
   "outputs": [],
   "source": [
    "def create_pos_pairs(spk_indices, L=45):\n",
    "    pos_pairs = list(combinations(spk_indices, 2))\n",
    "    return pos_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y67ez_HOgHT3"
   },
   "outputs": [],
   "source": [
    "def create_neg_pairs(spk_indices, other_indices, L=45):\n",
    "    neg_pairs = list(product(spk_indices, other_indices))\n",
    "    l_pairs = random.sample(neg_pairs, L)\n",
    "    return l_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTLwWbcTgHxp"
   },
   "outputs": [],
   "source": [
    "def generate_batches(data):\n",
    "    total_utterances = data.shape[0]\n",
    "    all_indices = list(range(total_utterances))\n",
    "    \n",
    "    left_input = []\n",
    "    right_input = []\n",
    "    output = []\n",
    "    \n",
    "    for i in range(0, total_utterances, 10):\n",
    "        speaker_indices = list(range(i, i+10))\n",
    "        pos_pairs = create_pos_pairs(speaker_indices)\n",
    "        other_indices = np.delete(all_indices, speaker_indices)\n",
    "        neg_pairs = create_neg_pairs(speaker_indices, other_indices)\n",
    "        \n",
    "        l_batch = []\n",
    "        r_batch = []\n",
    "        o_batch = []\n",
    "\n",
    "        for x, y in pos_pairs:\n",
    "            l_batch.append(data[x])\n",
    "            r_batch.append(data[y])\n",
    "            o_batch.append(1)\n",
    "\n",
    "        for x, y in neg_pairs:\n",
    "            l_batch.append(data[x])\n",
    "            r_batch.append(data[y])\n",
    "            o_batch.append(0)\n",
    "        \n",
    "        left_input.append(l_batch)\n",
    "        right_input.append(r_batch)\n",
    "        output.append(o_batch)\n",
    "    \n",
    "    return np.stack(left_input), np.stack(right_input), np.stack(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HY_g6fERgJMF"
   },
   "outputs": [],
   "source": [
    "left_train, right_train, y_train = generate_batches(train_data)\n",
    "left_test, right_test, y_test = generate_batches(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ijlyy17ihvzu",
    "outputId": "7a3af86f-843c-432f-e162-1a2e56e9764e"
   },
   "outputs": [],
   "source": [
    "print(left_train.shape, left_train.dtype)\n",
    "print(right_train.shape, right_train.dtype)\n",
    "print(y_train.shape,y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PhafvU0ghxPK",
    "outputId": "833636fd-b608-475b-d604-b0a4a3e22378"
   },
   "outputs": [],
   "source": [
    "print(left_test.shape, left_test.dtype)\n",
    "print(right_test.shape, right_test.dtype)\n",
    "print(y_test.shape,y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-5PDDMTNz5nf",
    "outputId": "fc8ef9df-489c-4ad2-ba9d-ca378a9c65d1"
   },
   "outputs": [],
   "source": [
    " y_train = y_train.astype(np.float32)\n",
    " print(y_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_yozc_D-zhs2",
    "outputId": "067183a3-fae6-41d4-83d0-bedc7d339e4e"
   },
   "outputs": [],
   "source": [
    " y_test = y_test.astype(np.float32)\n",
    " print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nURvCb3hyml"
   },
   "outputs": [],
   "source": [
    "def create_placeholders():\n",
    "  left_x = tf.placeholder(tf.float32,shape = (None,None,513))\n",
    "  right_x = tf.placeholder(tf.float32,shape = (None,None,513))\n",
    "  y = tf.placeholder(tf.float32,shape = (None))\n",
    "  rows = tf.placeholder(tf.int32)\n",
    "\n",
    "  return left_x, right_x, y, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x4_-fqBk1Crc"
   },
   "outputs": [],
   "source": [
    "def siamese_model(inputs, reuse, rows, num_units = [513]):\n",
    "  cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n, reuse = reuse) for n in num_units]\n",
    "  stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "  rnn_outputs, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, dtype = tf.float32)\n",
    "  hidden1 = tf.layers.dense(rnn_outputs, 513, activation=tf.nn.tanh, reuse = reuse)\n",
    "  drop_out = tf.nn.dropout(hidden1, keep_prob = 0.9)\n",
    "  outputs = tf.layers.dense(drop_out, 513, activation=tf.nn.relu, reuse = reuse)\n",
    "  outputs = tf.reshape(hidden1,shape = [-1, rows*513])\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJd9HEtKOAJh"
   },
   "outputs": [],
   "source": [
    "def model(train_data, test_data, learning_rate = 0.0005, num_epochs = 20):\n",
    "  tf.reset_default_graph()\n",
    "\n",
    "  x1, x2, y, rows  = create_placeholders()\n",
    "  left_train, right_train, y_train = train_data\n",
    "  left_test, right_test, y_test = test_data\n",
    "\n",
    "  left_op = siamese_model(x1,False,rows)\n",
    "  right_op = siamese_model(x2,True,rows)\n",
    "  dotProduct = tf.reduce_sum(tf.multiply(left_op,right_op),axis = 1)\n",
    "  yPred = tf.nn.sigmoid(dotProduct)\n",
    "\n",
    "  binarisedOutput = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
    "  \n",
    "  cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = dotProduct))\n",
    "  \n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "  init = tf.global_variables_initializer()\n",
    "\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        error = 0\n",
    "        i = 0\n",
    "        for x1_batch,x2_batch,y_batch in zip(left_train,right_train,y_train):\n",
    "          row = x1_batch.shape[1]\n",
    "          sess.run(optimizer,feed_dict = {x1 : x1_batch, x2: x2_batch, y:y_batch, rows:row })\n",
    "\n",
    "          error += sess.run(cost, feed_dict ={x1: x1_batch, x2: x2_batch, y:y_batch, rows:row })  \n",
    "          i += 1\n",
    "        \n",
    "        test_accuracy = 0.0\n",
    "        j = 0\n",
    "        for x1_batch,x2_batch,y_batch in zip(left_test,right_test,y_test):\n",
    "            row = x1_batch.shape[1]\n",
    "            y_pred = sess.run(binarisedOutput, feed_dict ={x1: x1_batch, x2: x2_batch, y:y_batch, rows: row})\n",
    "            test_accuracy += sum(y_pred == y_batch)\n",
    "            j+=1\n",
    "\n",
    "        print(epoch,\"Cost:\", error/i, \" Test Accuracy: \", test_accuracy/j)\n",
    "\n",
    "    test_accuracy = 0.0\n",
    "    j = 0\n",
    "    for x1_batch,x2_batch,y_batch in zip(left_test,right_test,y_test):\n",
    "      row = x1_batch.shape[1]\n",
    "      y_pred = sess.run(binarisedOutput, feed_dict ={x1: x1_batch, x2: x2_batch, y:y_batch, rows: row})\n",
    "      test_accuracy += sum(y_pred == y_batch)\n",
    "      j+=1\n",
    "    \n",
    "    print(\"Final Test Accuracy: \", test_accuracy/j)\n",
    "    return test_accuracy/j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8cr0PJePaQE"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "3XDBoBcCsl1v",
    "outputId": "ada8ec74-d227-4ab4-abc1-e1153fc84adf"
   },
   "outputs": [],
   "source": [
    "tr_data = [left_train, right_train, y_train.astype(float)]\n",
    "te_data = [left_test, right_test, y_test]\n",
    "acc = model(tr_data, te_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oaesEcXdKcxg"
   },
   "outputs": [],
   "source": [
    "print(\"Test Accuracy = \", acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "spk_ver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
