{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speaker Verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu5HQxe_vMoh",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVMyaKTbfnDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import random\n",
        "from itertools import combinations, product\n",
        "\n",
        "import pickle\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzE96aTfzUy5",
        "colab_type": "text"
      },
      "source": [
        "### Load Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z2pod13fyLL",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "9c04f3fb-33ef-4b2c-96bc-6bd0ef77ced9"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eff360ca-b734-4eab-aa2b-5a77298055cf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-eff360ca-b734-4eab-aa2b-5a77298055cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hw4_tes.pkl to hw4_tes.pkl\n",
            "Saving hw4_trs.pkl to hw4_trs.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKiP2vAsf2cC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f92bdf5-b4ce-4736-ffce-84fe25dc7f7f"
      },
      "source": [
        "with open('hw4_trs.pkl', 'rb') as pickle_file:\n",
        "    train_data = pickle.load(pickle_file)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 16180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERjzc8ZPf-iL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99bb2a34-b383-4e8d-e834-05fbe95a35f2"
      },
      "source": [
        "with open('hw4_tes.pkl', 'rb') as pickle_file:\n",
        "    test_data = pickle.load(pickle_file)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 22631)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V879fkbMgAEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in train_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcgCEbpogBs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in test_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFTMlToTzfsq",
        "colab_type": "text"
      },
      "source": [
        "### Create Positive Pairs\n",
        "Generates all 45 combinations of pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5czByMgES8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pos_pairs(spk_indices, L=45):\n",
        "    pos_pairs = list(combinations(spk_indices, 2))\n",
        "    return pos_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibb4uF9Yznsf",
        "colab_type": "text"
      },
      "source": [
        "### Create Negative Pairs\n",
        "A = indices of positive speaker's utterances  \n",
        "B = Indices of other speakers' utterances  \n",
        "Take the cartesian product of A and B and sample 45 pairs from it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y67ez_HOgHT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neg_pairs(spk_indices, other_indices, L=45):\n",
        "    neg_pairs = list(product(spk_indices, other_indices))\n",
        "    l_pairs = random.sample(neg_pairs, L)\n",
        "    return l_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jtQAPTzv04",
        "colab_type": "text"
      },
      "source": [
        "### Create Training and Testing Batches\n",
        "Creates 50 batches for Training and 20 Batches for Testing. Each batch has 45 pairs of negative examples and 45 pairs of positive examples, i.e, 90 total pairs in each batch.\n",
        "\n",
        "Final Dimensions of Training Data - Batches(50) x Pairs (90) x Transposed Shape of Spectrogram (32x513)\n",
        "\n",
        "Final Dimensions of Testing Data - Batches(20) x Pairs (90) x Transposed Shape of Spectrogram (45x513)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTLwWbcTgHxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(data):\n",
        "    total_utterances = data.shape[0]\n",
        "    all_indices = list(range(total_utterances))\n",
        "    \n",
        "    left_input = []\n",
        "    right_input = []\n",
        "    output = []\n",
        "    \n",
        "    for i in range(0, total_utterances, 10):\n",
        "        speaker_indices = list(range(i, i+10))\n",
        "        pos_pairs = create_pos_pairs(speaker_indices)\n",
        "        other_indices = np.delete(all_indices, speaker_indices)\n",
        "        neg_pairs = create_neg_pairs(speaker_indices, other_indices)\n",
        "        \n",
        "        l_batch = []\n",
        "        r_batch = []\n",
        "        o_batch = []\n",
        "\n",
        "        for x, y in pos_pairs:\n",
        "            l_batch.append(data[x])\n",
        "            r_batch.append(data[y])\n",
        "            o_batch.append(1)\n",
        "\n",
        "        for x, y in neg_pairs:\n",
        "            l_batch.append(data[x])\n",
        "            r_batch.append(data[y])\n",
        "            o_batch.append(0)\n",
        "        \n",
        "        left_input.append(l_batch)\n",
        "        right_input.append(r_batch)\n",
        "        output.append(o_batch)\n",
        "    \n",
        "    return np.stack(left_input), np.stack(right_input), np.stack(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_g6fERgJMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_train, right_train, y_train = generate_batches(train_data)\n",
        "left_test, right_test, y_test = generate_batches(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijlyy17ihvzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2b46e7cb-fba1-4468-a118-dd2dded1ebd9"
      },
      "source": [
        "print(left_train.shape, left_train.dtype)\n",
        "print(right_train.shape, right_train.dtype)\n",
        "print(y_train.shape,y_train.dtype)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 90, 32, 513) float32\n",
            "(50, 90, 32, 513) float32\n",
            "(50, 90) int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhafvU0ghxPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ac0fe976-ae29-44f5-ec37-49d81019dd68"
      },
      "source": [
        "print(left_test.shape, left_test.dtype)\n",
        "print(right_test.shape, right_test.dtype)\n",
        "print(y_test.shape,y_test.dtype)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 90, 45, 513) float32\n",
            "(20, 90, 45, 513) float32\n",
            "(20, 90) int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5PDDMTNz5nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3993a0d-a89c-4149-a27c-14cd0e66ff22"
      },
      "source": [
        " y_train = y_train.astype(np.float32)\n",
        " print(y_train.dtype)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yozc_D-zhs2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35e2b860-ec23-4b38-c3c5-d291a139b32f"
      },
      "source": [
        " y_test = y_test.astype(np.float32)\n",
        " print(y_test.dtype)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_d-K41Kz1IK",
        "colab_type": "text"
      },
      "source": [
        "### Create Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nURvCb3hyml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders():\n",
        "  left_x = tf.placeholder(tf.float32,shape = [None,None,513])\n",
        "  right_x = tf.placeholder(tf.float32,shape = [None,None,513])\n",
        "  y = tf.placeholder(tf.float32,shape = [None])\n",
        "  rows = tf.placeholder(tf.int32)\n",
        "\n",
        "  return left_x, right_x, y, rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFv4yA8Ez31-",
        "colab_type": "text"
      },
      "source": [
        "### Defines the Base of the Siamese Model\n",
        "Uses an LSTM Layer followed by a Dense Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_-fqBk1Crc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siamese_model(inputs, reuse, rows, num_units = [513]):\n",
        "  cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n, reuse = reuse) for n in num_units]\n",
        "  stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
        "  rnn_op, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, dtype = tf.float32)\n",
        "  dense_1 = tf.layers.dense(rnn_op, 513, activation=tf.nn.tanh, reuse = reuse)\n",
        "  output = tf.reshape(dense_1,shape = [-1, rows*513])\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM98k0lJz7jw",
        "colab_type": "text"
      },
      "source": [
        "### Define Complete Model\n",
        "Total Number of Epochs =  100\n",
        "Learning rate =  0.0005\n",
        "Optimizer = Adam  \n",
        "Loss Funtion = Sigmoid Cross Entropy  \n",
        "Cost is the mean of all the losses for each prediction  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vMiNf17uO7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(train_data, test_data, learning_rate = 0.0005, num_epochs = 100):\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  x1, x2, y, rows  = create_placeholders()\n",
        "  left_train, right_train, y_train = train_data\n",
        "  left_test, right_test, y_test = test_data\n",
        "\n",
        "  left_op = siamese_model(x1,False,rows)\n",
        "  right_op = siamese_model(x2,True,rows)\n",
        "  dot_prod = tf.reduce_sum(tf.multiply(left_op,right_op),axis = 1)\n",
        "  yPred = tf.nn.sigmoid(dot_prod)\n",
        "\n",
        "  binary_op = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
        "  \n",
        "  cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = dot_prod))\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        i = 0\n",
        "        for left, right, y_batch in zip(left_train,right_train,y_train):\n",
        "          row = left.shape[1]\n",
        "\n",
        "          _, batch_loss = sess.run([optimizer, cost], feed_dict ={x1: left, x2: right, y:y_batch, rows:row })  \n",
        "          epoch_loss += batch_loss\n",
        "          i += 1\n",
        "        \n",
        "        test_accuracy = 0.0\n",
        "        j = 0\n",
        "        for left,right,y_batch in zip(left_test,right_test,y_test):\n",
        "            row = left.shape[1]\n",
        "            y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
        "            test_accuracy += sum(y_pred == y_batch)\n",
        "            j+=1\n",
        "\n",
        "        print(epoch,\"Cost:\", epoch_loss/i, \" Test Accuracy: \", test_accuracy/j)\n",
        "\n",
        "    test_accuracy = 0.0\n",
        "    j = 0\n",
        "    for left,right,y_batch in zip(left_test,right_test,y_test):\n",
        "      row = left.shape[1]\n",
        "      y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
        "      test_accuracy += sum(y_pred == y_batch)\n",
        "      j+=1\n",
        "    \n",
        "    print(\"Final Test Accuracy: \", test_accuracy/j)\n",
        "    return test_accuracy/j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg9qDES60DPO",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoO9Pi2QuSmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d29c64d-7c05-43a3-e497-c1e23cc6b541"
      },
      "source": [
        "tr_data = [left_train, right_train, y_train.astype(float)]\n",
        "te_data = [left_test, right_test, y_test]\n",
        "acc = model(tr_data, te_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Cost: 453.4048374938965  Test Accuracy:  58.0\n",
            "1 Cost: 56.70241477966309  Test Accuracy:  59.95\n",
            "2 Cost: 47.25871959686279  Test Accuracy:  60.3\n",
            "3 Cost: 42.841072425842285  Test Accuracy:  60.2\n",
            "4 Cost: 39.38418025970459  Test Accuracy:  60.5\n",
            "5 Cost: 36.035656509399416  Test Accuracy:  60.4\n",
            "6 Cost: 32.03628219604492  Test Accuracy:  59.25\n",
            "7 Cost: 27.979810390472412  Test Accuracy:  58.6\n",
            "8 Cost: 23.48279716491699  Test Accuracy:  57.4\n",
            "9 Cost: 18.895699195861816  Test Accuracy:  56.4\n",
            "10 Cost: 14.67335750579834  Test Accuracy:  56.8\n",
            "11 Cost: 11.403266553878785  Test Accuracy:  56.0\n",
            "12 Cost: 8.785487184524536  Test Accuracy:  55.85\n",
            "13 Cost: 10.145658259391785  Test Accuracy:  52.4\n",
            "14 Cost: 12.079624485969543  Test Accuracy:  53.45\n",
            "15 Cost: 12.69576623916626  Test Accuracy:  55.75\n",
            "16 Cost: 9.179578392505645  Test Accuracy:  51.45\n",
            "17 Cost: 7.961005117893219  Test Accuracy:  54.0\n",
            "18 Cost: 9.643432326316834  Test Accuracy:  52.65\n",
            "19 Cost: 6.654852335453033  Test Accuracy:  56.5\n",
            "20 Cost: 5.092384368181229  Test Accuracy:  52.25\n",
            "21 Cost: 3.42645193696022  Test Accuracy:  55.75\n",
            "22 Cost: 2.310688437819481  Test Accuracy:  53.75\n",
            "23 Cost: 2.0525220227986574  Test Accuracy:  57.3\n",
            "24 Cost: 0.936473538838327  Test Accuracy:  57.35\n",
            "25 Cost: 0.7175355750694871  Test Accuracy:  56.45\n",
            "26 Cost: 0.40626593939960004  Test Accuracy:  59.2\n",
            "27 Cost: 0.26181295680813493  Test Accuracy:  60.95\n",
            "28 Cost: 0.0883030349900946  Test Accuracy:  61.4\n",
            "29 Cost: 0.042735771799925715  Test Accuracy:  61.35\n",
            "30 Cost: 0.032454220799263564  Test Accuracy:  61.1\n",
            "31 Cost: 0.027416240060701966  Test Accuracy:  61.0\n",
            "32 Cost: 0.023875273454468698  Test Accuracy:  61.05\n",
            "33 Cost: 0.021136599973542617  Test Accuracy:  61.05\n",
            "34 Cost: 0.018931142634246497  Test Accuracy:  61.05\n",
            "35 Cost: 0.017108326685847716  Test Accuracy:  61.1\n",
            "36 Cost: 0.015572251124540344  Test Accuracy:  61.15\n",
            "37 Cost: 0.014257902073441074  Test Accuracy:  61.1\n",
            "38 Cost: 0.013119255728088319  Test Accuracy:  61.15\n",
            "39 Cost: 0.012122621707385406  Test Accuracy:  61.2\n",
            "40 Cost: 0.011242684682365507  Test Accuracy:  61.2\n",
            "41 Cost: 0.01045998745423276  Test Accuracy:  61.2\n",
            "42 Cost: 0.009759289414505474  Test Accuracy:  61.25\n",
            "43 Cost: 0.009128452473087236  Test Accuracy:  61.25\n",
            "44 Cost: 0.0085576919070445  Test Accuracy:  61.25\n",
            "45 Cost: 0.00803899066755548  Test Accuracy:  61.3\n",
            "46 Cost: 0.007565728018525988  Test Accuracy:  61.4\n",
            "47 Cost: 0.007132380144903436  Test Accuracy:  61.45\n",
            "48 Cost: 0.006734290134045295  Test Accuracy:  61.4\n",
            "49 Cost: 0.006367507144459523  Test Accuracy:  61.4\n",
            "50 Cost: 0.006028653348912485  Test Accuracy:  61.5\n",
            "51 Cost: 0.005714822102454491  Test Accuracy:  61.4\n",
            "52 Cost: 0.005423494239803404  Test Accuracy:  61.45\n",
            "53 Cost: 0.005152482204139232  Test Accuracy:  61.45\n",
            "54 Cost: 0.00489987107925117  Test Accuracy:  61.45\n",
            "55 Cost: 0.00466397522657644  Test Accuracy:  61.45\n",
            "56 Cost: 0.0044433110259706156  Test Accuracy:  61.45\n",
            "57 Cost: 0.00423656044062227  Test Accuracy:  61.5\n",
            "58 Cost: 0.004042552722676191  Test Accuracy:  61.5\n",
            "59 Cost: 0.0038602448644815012  Test Accuracy:  61.5\n",
            "60 Cost: 0.0036887030547950415  Test Accuracy:  61.55\n",
            "61 Cost: 0.0035270861370372587  Test Accuracy:  61.55\n",
            "62 Cost: 0.003374638116802089  Test Accuracy:  61.55\n",
            "63 Cost: 0.003230678694089875  Test Accuracy:  61.55\n",
            "64 Cost: 0.0030945873554446735  Test Accuracy:  61.55\n",
            "65 Cost: 0.0029658028029371053  Test Accuracy:  61.5\n",
            "66 Cost: 0.0028438170420122333  Test Accuracy:  61.5\n",
            "67 Cost: 0.0027281652137753553  Test Accuracy:  61.5\n",
            "68 Cost: 0.002618421447405126  Test Accuracy:  61.5\n",
            "69 Cost: 0.0025141977510065774  Test Accuracy:  61.5\n",
            "70 Cost: 0.002415137654315913  Test Accuracy:  61.5\n",
            "71 Cost: 0.0023209136640070936  Test Accuracy:  61.45\n",
            "72 Cost: 0.002231224096613005  Test Accuracy:  61.4\n",
            "73 Cost: 0.00214579333725851  Test Accuracy:  61.4\n",
            "74 Cost: 0.002064364418038167  Test Accuracy:  61.45\n",
            "75 Cost: 0.001986699462577235  Test Accuracy:  61.5\n",
            "76 Cost: 0.0019125794147839769  Test Accuracy:  61.5\n",
            "77 Cost: 0.001841801866394235  Test Accuracy:  61.5\n",
            "78 Cost: 0.0017741781190852635  Test Accuracy:  61.6\n",
            "79 Cost: 0.0017095311006414704  Test Accuracy:  61.6\n",
            "80 Cost: 0.0016476998089638073  Test Accuracy:  61.6\n",
            "81 Cost: 0.0015885302399692592  Test Accuracy:  61.65\n",
            "82 Cost: 0.0015318818925879895  Test Accuracy:  61.7\n",
            "83 Cost: 0.0014776199657353572  Test Accuracy:  61.65\n",
            "84 Cost: 0.0014256221061805263  Test Accuracy:  61.7\n",
            "85 Cost: 0.0013757737436390016  Test Accuracy:  61.7\n",
            "86 Cost: 0.0013279631608747878  Test Accuracy:  61.7\n",
            "87 Cost: 0.0012820901500526815  Test Accuracy:  61.75\n",
            "88 Cost: 0.0012380597781157122  Test Accuracy:  61.65\n",
            "89 Cost: 0.001195782098075142  Test Accuracy:  61.65\n",
            "90 Cost: 0.0011551712325308472  Test Accuracy:  61.75\n",
            "91 Cost: 0.0011161490733502433  Test Accuracy:  61.65\n",
            "92 Cost: 0.00107864182558842  Test Accuracy:  61.65\n",
            "93 Cost: 0.0010425781161757185  Test Accuracy:  61.65\n",
            "94 Cost: 0.0010078902015811764  Test Accuracy:  61.7\n",
            "95 Cost: 0.0009745164011110319  Test Accuracy:  61.7\n",
            "96 Cost: 0.0009423972399235936  Test Accuracy:  61.7\n",
            "97 Cost: 0.0009114777422655607  Test Accuracy:  61.7\n",
            "98 Cost: 0.0008817024533345829  Test Accuracy:  61.7\n",
            "99 Cost: 0.0008530243558925577  Test Accuracy:  61.7\n",
            "Final Test Accuracy:  61.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc4n55G30M2l",
        "colab_type": "text"
      },
      "source": [
        "### Final Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_xbWdObuVXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1b48948-7ae3-4285-a8f5-6628fb08cda9"
      },
      "source": [
        "print(\"Test Accuracy = \", acc)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy =  61.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fylqd1ym09w4",
        "colab_type": "text"
      },
      "source": [
        "### Things I tried\n",
        "Models - \n",
        "1. Stacking Convolution Layers and using Euclidean Distance between embeddings\n",
        "2. Stacking GRUs\n",
        "3. ConvLSTM2D\n",
        "4. BinaryCrossEntropy Loss and Contrasive Loss\n",
        "\n",
        "Used to get stuck at Test accuracy at 50% using the above models which were built using keras. I think the model wasn't reusing the weights so I built a new Siamese model just LSTM without keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de-84D2dEeMP",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "1. https://keras.io/examples/mnist_siamese/\n",
        "2. https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0\n",
        "3. https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
        "4. https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emNg1WJrEdK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXocFt_zuzUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
