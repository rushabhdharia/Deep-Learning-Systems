{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPool2D, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6265, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_tr7.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1028, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_te7.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Channel Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(train_data, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.expand_dims(test_data, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAE_model(ip_shape = [28, 28, 1], latent_dim = 4):\n",
    "    input_img = Input(ip_shape) \n",
    "    \n",
    "    encoder_model = Sequential()   \n",
    "    encoder_model.add(Conv2D(16, kernel_size = (5, 5), input_shape = ip_shape, activation = 'relu'))\n",
    "    encoder_model.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu'))\n",
    "    encoder_model.add(Conv2D(64, kernel_size = (2, 2), activation = 'relu'))\n",
    "    encoder_model.add(Flatten())\n",
    "    encoder_model.add(Dense(128))\n",
    "    \n",
    "    encoder_output = encoder_model(input_img)\n",
    "    \n",
    "    z_mean = Dense(latent_dim)(encoder_output)\n",
    "    z_log_var = Dense(latent_dim)(encoder_output)\n",
    "     \n",
    "    epsilon =  K.random_normal(shape=K.shape(z_mean))\n",
    "    #reparameterize\n",
    "    z = z_mean + K.exp(0.5 + z_log_var) * epsilon\n",
    "    \n",
    "    decoder_model = Sequential()\n",
    "    decoder_model.add(Dense(latent_dim*2, input_shape = z.get_shape(), activation = 'relu'))\n",
    "    decoder_model.add(Dense(28*28, activation = 'relu'))\n",
    "    decoder_model.add(Reshape(target_shape = (28,28, 1)))\n",
    "    decoder_model.add(Conv2DTranspose(64, kernel_size = (2, 2), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(32, kernel_size = (3, 3), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(16, kernel_size = (5, 5), activation = 'relu', padding='SAME'))\n",
    "    decoder_model.add(Conv2DTranspose(1, kernel_size = (5, 5), padding='SAME'))\n",
    "    \n",
    "    prediction = decoder_model(z)\n",
    "      \n",
    "    vae_model = Model(inputs = input_img, outputs = prediction)\n",
    "    \n",
    "    return vae_model, z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELBO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(ip, op):\n",
    "    kld = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    bce = tf.losses.sigmoid_cross_entropy(ip, op)\n",
    "    \n",
    "    return bce+kld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rushabh/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/rushabh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vae_model, z_mean, z_log_var = VAE_model() \n",
    "vae_model.compile(loss=vae_loss,optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6265 samples, validate on 1028 samples\n",
      "Epoch 1/50\n",
      "6265/6265 [==============================] - 48s 8ms/sample - loss: 0.2782 - val_loss: 0.2423\n",
      "Epoch 2/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2435 - val_loss: 0.2398\n",
      "Epoch 3/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2426 - val_loss: 0.2414\n",
      "Epoch 4/50\n",
      "6265/6265 [==============================] - 43s 7ms/sample - loss: 0.2422 - val_loss: 0.2392\n",
      "Epoch 5/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2419 - val_loss: 0.2389\n",
      "Epoch 6/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2419 - val_loss: 0.2388\n",
      "Epoch 7/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2417 - val_loss: 0.2408\n",
      "Epoch 8/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2414 - val_loss: 0.2388\n",
      "Epoch 9/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2416 - val_loss: 0.2388\n",
      "Epoch 10/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2413 - val_loss: 0.2383\n",
      "Epoch 11/50\n",
      "6265/6265 [==============================] - 42s 7ms/sample - loss: 0.2412 - val_loss: 0.2386\n",
      "Epoch 12/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2412 - val_loss: 0.2388\n",
      "Epoch 13/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2412 - val_loss: 0.2395\n",
      "Epoch 14/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2412 - val_loss: 0.2382\n",
      "Epoch 15/50\n",
      "6265/6265 [==============================] - 41s 7ms/sample - loss: 0.2411 - val_loss: 0.2385\n",
      "Epoch 16/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2410 - val_loss: 0.2383\n",
      "Epoch 17/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2411 - val_loss: 0.2397\n",
      "Epoch 18/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2411 - val_loss: 0.2387\n",
      "Epoch 19/50\n",
      "6265/6265 [==============================] - 43s 7ms/sample - loss: 0.2410 - val_loss: 0.2382\n",
      "Epoch 20/50\n",
      "6265/6265 [==============================] - 45s 7ms/sample - loss: 0.2410 - val_loss: 0.2383\n",
      "Epoch 21/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2410 - val_loss: 0.2382\n",
      "Epoch 22/50\n",
      "6265/6265 [==============================] - 43s 7ms/sample - loss: 0.2409 - val_loss: 0.2386\n",
      "Epoch 23/50\n",
      "6265/6265 [==============================] - 44s 7ms/sample - loss: 0.2409 - val_loss: 0.2398\n",
      "Epoch 24/50\n",
      " 512/6265 [=>............................] - ETA: 39s - loss: 0.2405"
     ]
    }
   ],
   "source": [
    "vae_model.fit(train_data, train_data, batch_size=16, epochs=50, shuffle = True, validation_data = (test_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model.save('vae.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model_2 = model.load('vae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://www.tensorflow.org/tutorials/generative/cvae\n",
    "2. https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
