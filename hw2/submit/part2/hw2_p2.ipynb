{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oA8Vlj_WjrP_"
   },
   "source": [
    "# Speech Denoising using 2D CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bO2_Q2Qp9oCd"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8uvm7FmVjd6B"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5JJkPa_9stY"
   },
   "source": [
    "### Upload Files\n",
    "Please upload the following files -\n",
    "\n",
    "1.   train_clean_male.wav\n",
    "2.   train_dirty_male.wav\n",
    "3.   test_x_01.wav\n",
    "4.   test_x_02.wav\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "jIPeOctrjo13",
    "outputId": "3d49f09d-b6a5-4362-d769-951738ade3cd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7703ac29-4dec-4e4d-bb95-d40bbd84525c\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-7703ac29-4dec-4e4d-bb95-d40bbd84525c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_x_01.wav to test_x_01.wav\n",
      "Saving test_x_02.wav to test_x_02.wav\n",
      "Saving train_clean_male.wav to train_clean_male.wav\n",
      "Saving train_dirty_male.wav to train_dirty_male.wav\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4HA6gpA-IjD"
   },
   "source": [
    "### Convert to Time_Frequency Domain\n",
    "Convert the signal from time domain to frequency domain and take the absolute.  \n",
    "Also taking the transpose of the absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "252hQj51jq6H"
   },
   "outputs": [],
   "source": [
    "s, sr = librosa.load('train_clean_male.wav', sr = None)\n",
    "S_clean = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "S_mag = np.abs(S_clean).T\n",
    "\n",
    "sn, sr = librosa.load('train_dirty_male.wav', sr = None)\n",
    "X_dirty = librosa.stft(s, n_fft=1024, hop_length=512)\n",
    "X_mag = np.abs(X_dirty).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWUtt-KzJymu"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l9w27e43-HVm"
   },
   "source": [
    "### Create Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqtrPjL2j0cX"
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x = 513, n_y = 513):\n",
    "  X = tf.placeholder(tf.float32, [None, 20, n_x])\n",
    "  Y = tf.placeholder(tf.float32, [None, n_y])\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ar1ltK6L-mx5"
   },
   "source": [
    "### Convolution 2D\n",
    "As mentioned by Prof. Kim to not use any zero padding, I've used VALID padding.  \n",
    "Stride by default is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8mOF2tNj5Ab"
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, stride = 1):\n",
    "  x = tf.nn.conv2d(x, W, strides = [1, stride, stride, 1], padding = 'VALID')\n",
    "  x = tf.nn.bias_add(x, b)\n",
    "  return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ttN12TH9-_nt"
   },
   "source": [
    "### MaxPooling 2D\n",
    "ksize and strides by default is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjdSs91nms8y"
   },
   "outputs": [],
   "source": [
    "def max_pool2d(x, k = 2):\n",
    "  return tf.nn.max_pool2d(x, ksize = [1, k, k, 1], strides = [1, k, k, 1], padding = 'VALID') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQ94Ftlu_LRB"
   },
   "source": [
    "### Initialize Parameters\n",
    "\n",
    "Used He initialization for weights and kernels.  \n",
    "Used Zeros Initializer for biases.\n",
    "\n",
    "1.   W1 is a 5x5 kernel with 16 channels\n",
    "2.   b1 is the bias added to the first Convolution layer\n",
    "3. W2 is a 5x5 kernel with 32 channels \n",
    "4. b2 is the bias added to the second Convolution layer\n",
    "5. W3 and b3 are the weights and biases respectively for the 3rd Layer which is a Fully Connected Layer\n",
    "6. W4 and b4 are the weights and biases respectively for the 3rd Layer which is a Fully Connected Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cV5W7jTvm--6"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "  W1 = tf.get_variable(\"W1\", [5, 5, 1, 16], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "  b1 = tf.get_variable(\"b1\", [16], initializer=tf.zeros_initializer)\n",
    " \n",
    "  W2 = tf.get_variable(\"W2\", [5, 5, 16, 32], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "  b2 = tf.get_variable(\"b2\", [32], initializer=tf.zeros_initializer)\n",
    "  \n",
    "  W3 = tf.get_variable(\"W3\", [1024, 8000], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "  b3 = tf.get_variable(\"b3\", [1024, 1], initializer=tf.zeros_initializer) \n",
    "\n",
    "  W4 = tf.get_variable(\"W4\", [513, 1024], initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "  b4 = tf.get_variable(\"b4\", [513, 1], initializer=tf.zeros_initializer)\n",
    "  \n",
    "\n",
    "  parameters = {\n",
    "      \"W1\" : W1,\n",
    "      \"b1\" : b1,\n",
    "      \"W2\" : W2,\n",
    "      \"b2\" : b2,\n",
    "      \"W3\" : W3,\n",
    "      \"b3\" : b3,\n",
    "      \"W4\" : W4,\n",
    "      \"b4\" : b4\n",
    "  }\n",
    "  \n",
    "  return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WBsIjYuA8Ki"
   },
   "source": [
    "### Forward Propagation\n",
    "The input is reshaped so that it has 4 dimensions - batchsize, height, width and number of channels.  \n",
    "The layers are as follows\n",
    "1. Convolution \n",
    "2. Pooling\n",
    "3. Convolution \n",
    "4. Pooling\n",
    "5. Fully Connected\n",
    "6. Fully Connected\n",
    "\n",
    "The Output dimensions are batch_size x width(513)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXUAIngwohuA"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "\n",
    "  X = tf.reshape(X, [-1, 20, 513, 1])\n",
    "  W1 = parameters['W1']\n",
    "  b1 = parameters['b1']\n",
    "  A1 = conv2d(X, W1, b1, stride = 1)\n",
    "  A1 = max_pool2d(A1, k=2)\n",
    "  \n",
    "  W2 = parameters['W2']\n",
    "  b2 = parameters['b2']\n",
    "  A2 = conv2d(A1, W2, b2, stride = 1)\n",
    "  A2 = max_pool2d(A2, k=2)\n",
    "  A2 = tf.transpose(tf.reshape(A2, [-1, A2.shape[1] * A2.shape[2] * A2.shape[3] ] ))\n",
    "\n",
    "  W3 = parameters['W3']\n",
    "  b3 = parameters['b3']\n",
    "  Z3 = tf.matmul(W3, A2) + b3\n",
    "  A3 = tf.nn.relu(Z3)\n",
    "  \n",
    "  W4 = parameters['W4']\n",
    "  b4 = parameters['b4']\n",
    "  Z4 = tf.matmul(W4, A3) + b4\n",
    "\n",
    "  return tf.transpose(Z4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8Pn7X0LDeuQ"
   },
   "source": [
    "### Create Images\n",
    "We create images of dimensions 20x513 for 2D convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_lhjz1hr7rX"
   },
   "outputs": [],
   "source": [
    "def create_images(input):\n",
    "\n",
    "  batches = []\n",
    "  start = 0\n",
    "  while start<input.shape[0]-19:\n",
    "    end = start+20\n",
    "    batches.append(input[start:end, :])\n",
    "    start += 1\n",
    "   \n",
    "    \n",
    "  return np.array(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Drqli2NztAIs",
    "outputId": "b72e85f8-638c-49e2-ea01-5e535e3519d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2440, 20, 513)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_images = create_images(X_mag)\n",
    "X_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgXUYyKwD5zH"
   },
   "source": [
    "### Compute Cost\n",
    "Loss function - MSE  \n",
    "Cost is the mean of all losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Kuv_81PwdvC"
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "\n",
    "  cost = tf.reduce_mean(tf.losses.mean_squared_error(tf.nn.relu(Z4), Y))\n",
    "  \n",
    "  return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FGOs9hkwEAuI"
   },
   "source": [
    "### Initialize Model for Training\n",
    "\n",
    "\n",
    "1.   Epochs = 100\n",
    "2.   Learning Rate = 2e4\n",
    "3. Minibatch Size = 16\n",
    "4. Optimizer - Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u7YAmv3a9Jdw"
   },
   "outputs": [],
   "source": [
    "def model(X_mag, S_mag, learning_rate = 0.0002, epochs = 200, print_cost = True, minibatch_size = 16):\n",
    "  \n",
    "  tf.reset_default_graph()\n",
    "  m = X_mag.shape[0]\n",
    "  X, Y = create_placeholders()\n",
    "  parameters = initialize_parameters()\n",
    "  \n",
    "  Z4 = forward_propagation(X, parameters)\n",
    "\n",
    "  cost = compute_cost(Z4, Y)\n",
    "  \n",
    "  optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "  init = tf.global_variables_initializer()\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "      epoch_cost = 0.\n",
    "      \n",
    "      num_minibatches = m//minibatch_size\n",
    "      \n",
    "      for i in range(num_minibatches+1):\n",
    "        start = i*minibatch_size\n",
    "        if i<num_minibatches:\n",
    "          end = start + minibatch_size\n",
    "          mini_X = X_mag[start:end, :, :]\n",
    "          mini_Y = S_mag[start:end, :]\n",
    "        else:\n",
    "          mini_X = X_mag[start:, :, :]\n",
    "          mini_Y = S_mag[start:, :]\n",
    "        \n",
    "        _, minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: mini_X, Y:mini_Y})\n",
    "        \n",
    "        epoch_cost += minibatch_cost / num_minibatches\n",
    "                               \n",
    "      if print_cost == True and (epoch % 10 == 0 or epoch == (epochs-1)):\n",
    "        print(\"Cost after epoch %i: %f\" %(epoch, epoch_cost))\n",
    "        \n",
    "      if print_cost == True and epoch % 5 == 0:\n",
    "        costs.append(epoch_cost)\n",
    "        \n",
    "    parameters = sess.run(parameters)\n",
    "    print (\"Parameters have been trained!\")\n",
    "\n",
    "    sess.close()\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_CcfvnPJKPi"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "gIHYmu9GDdaU",
    "outputId": "b1d79c2a-a17a-4b08-8dd7-62f71f5c4c78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.257478\n",
      "Cost after epoch 10: 0.075119\n",
      "Cost after epoch 20: 0.038676\n",
      "Cost after epoch 30: 0.028056\n",
      "Cost after epoch 40: 0.023496\n",
      "Cost after epoch 50: 0.018783\n",
      "Cost after epoch 60: 0.017085\n",
      "Cost after epoch 70: 0.015653\n",
      "Cost after epoch 80: 0.011903\n",
      "Cost after epoch 90: 0.011365\n",
      "Cost after epoch 100: 0.009074\n",
      "Cost after epoch 110: 0.007725\n",
      "Cost after epoch 120: 0.007954\n",
      "Cost after epoch 130: 0.007159\n",
      "Cost after epoch 140: 0.006056\n",
      "Cost after epoch 150: 0.005806\n",
      "Cost after epoch 160: 0.005040\n",
      "Cost after epoch 170: 0.004692\n",
      "Cost after epoch 180: 0.004267\n",
      "Cost after epoch 190: 0.004139\n",
      "Cost after epoch 199: 0.004194\n",
      "Parameters have been trained!\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_images, S_mag[19:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SEbDYpwhGeFB"
   },
   "source": [
    "### Append Silent Frames\n",
    "Append with 19 Silent frames to match the output dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h3X2LJUHxTb0"
   },
   "outputs": [],
   "source": [
    "def append_silent_frames(input):\n",
    "  to_append = np.array([[np.random.rand() for j in range(513)]for i in range(19)])\n",
    "  return np.concatenate((to_append, input), axis =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ied2wFquH01u"
   },
   "source": [
    "### Clean  \n",
    "\n",
    "1.   Forward propagation on trained Network\n",
    "2.   Input - Noisy Signal appended with 19 silent frames and converted to images of dimensions 20x513\n",
    "3. Output - Clean Signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MJc-I1iryqB"
   },
   "outputs": [],
   "source": [
    "def clean(X_mag, parameters):\n",
    "  tf.reset_default_graph()\n",
    "  \n",
    "  X = tf.placeholder(tf.float32, [None, 20, 513])\n",
    "  Z4 = forward_propagation(X, parameters)\n",
    "  S_test = tf.nn.relu(Z4) \n",
    "  \n",
    "  init = tf.global_variables_initializer()\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    S_test = sess.run(S_test, feed_dict = {X: X_mag})\n",
    "    \n",
    "    sess.close()\n",
    "  return S_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0WcEq7y-Kpha"
   },
   "source": [
    "#### Clean the training data \n",
    "\n",
    "\n",
    "1.   Append silent frames\n",
    "2.   Create images of dimensions 20x513\n",
    "3. Feed the images to the trained network to get the clean signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NgrC7FQFr5OQ",
    "outputId": "52707bd0-1048-4650-bb38-a7dea1a24fb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2459, 513)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mag_new = append_silent_frames(X_mag)\n",
    "X_images_new = create_images(X_mag_new)\n",
    "c1 = clean(X_images_new, parameters)\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rhq-o0AlMjHU"
   },
   "source": [
    "### Recover the Complex Valued Spectrogram\n",
    "Recovering the complex valued Spectrogram and applying inverse STFT to convert from time-frequency domain to time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ysIo71F1r_Bk"
   },
   "outputs": [],
   "source": [
    "S = np.multiply(np.divide(X_dirty.T, X_mag), c1)\n",
    "sh_test = librosa.istft(S.T, win_length=1024 ,hop_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VzG-kQE2NZWt"
   },
   "source": [
    "### Saving the cleaned signal and downloading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xeRndEX02ws"
   },
   "outputs": [],
   "source": [
    "librosa.output.write_wav('test_clean_male.wav', sh_test, sr)\n",
    "files.download('test_clean_male.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMwxPhmcM0ew"
   },
   "source": [
    "### SNR\n",
    "Calculate the SNR of the train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xy5t-zfV04FS"
   },
   "outputs": [],
   "source": [
    "def snr(clean, recon):\n",
    "  if len(recon)> len(clean):\n",
    "    new = np.zeros(len(recon)-len(clean))\n",
    "    clean = np.concatenate([clean, new])\n",
    "  \n",
    "  elif len(recon)< len(clean):\n",
    "      new = np.zeros(len(clean)-len(recon))\n",
    "      recon = np.concatenate([recon, new])\n",
    "  \n",
    "  return 10*np.log10(np.sum(clean**2)/np.sum(clean**2 - recon**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vq1Iq6CD05ku",
    "outputId": "7c96fd38-5d4a-4ddd-ef88-768275f6db00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.178626987161065"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snr(s, sh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGTRRyHTTw_0"
   },
   "source": [
    "## For test_x_01.wav\n",
    "Load the file -> transform to feature domain using stft and take magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbOQCY2907Rm"
   },
   "outputs": [],
   "source": [
    "test1, sr = librosa.load('test_x_01.wav', sr = None)\n",
    "t1_dirty = librosa.stft(test1, n_fft=1024, hop_length=512)\n",
    "t1_mag = np.abs(t1_dirty).T    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uaWHiIw9T6w-"
   },
   "source": [
    "1. Append silent frames\n",
    "2. Create images of dimension 20x513\n",
    "3. Clean the signal using the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-zz3ub62FzN"
   },
   "outputs": [],
   "source": [
    "t1_new = append_silent_frames(t1_mag)\n",
    "t1_images = create_images(t1_new)\n",
    "clean_t1 = clean(t1_images, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XJtisFpVUTkY"
   },
   "source": [
    "Recover Complex Valued Speech Spectrogram  \n",
    "And apply inverse STFT to convert from requency domain to time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nwPg0PWy41Zt"
   },
   "outputs": [],
   "source": [
    "T1 = np.multiply(np.divide(t1_dirty, t1_mag.T), clean_t1.T)\n",
    "test_01 = librosa.istft(T1, win_length=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nv8RlsdeUY0H"
   },
   "source": [
    "Save the cleaned signal and download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sEngKme5dDc"
   },
   "outputs": [],
   "source": [
    "librosa.output.write_wav('test_s_01_recons.wav', test_01, sr)\n",
    "files.download('test_s_01_recons.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEnFmur-Udgw"
   },
   "source": [
    "## For test_x_02.wav\n",
    "Load the file -> transform to feature domain using stft and take magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5ItPtkA8n8O"
   },
   "outputs": [],
   "source": [
    "test2, sr = librosa.load('test_x_02.wav', sr = None)\n",
    "t2_dirty = librosa.stft(test2, n_fft=1024, hop_length=512)\n",
    "t2_mag = np.abs(t2_dirty).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LYp901rvUyp8"
   },
   "source": [
    "1. Append silent frames\n",
    "2. Create images of dimension 20x513\n",
    "3. Clean the signal using the trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D-7pWpCB8pnc",
    "outputId": "67cf87fd-c1bf-4e97-e11d-9ee9163205ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 513)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_new = append_silent_frames(t2_mag)\n",
    "t2_images = create_images(t2_new)\n",
    "clean_t2 = clean(t2_images, parameters)\n",
    "clean_t2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UPv2KgTU5B8"
   },
   "source": [
    "Recover Complex Valued Speech Spectrogram\n",
    "And apply inverse STFT to convert from requency domain to time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjo_tgwI8r3f"
   },
   "outputs": [],
   "source": [
    "T2 = np.multiply(np.divide(t2_dirty, t2_mag.T), clean_t2.T)\n",
    "test_02 = librosa.istft(T2, win_length=1024, hop_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kc3qrOsUU63A"
   },
   "source": [
    "Save the cleaned signal and download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BcctBLS8tP_"
   },
   "outputs": [],
   "source": [
    "librosa.output.write_wav('test_s_02_recons.wav', test_02, sr)\n",
    "files.download('test_s_02_recons.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7-eSwryVaDm"
   },
   "source": [
    "## Hyperparameters Used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fdAQ5G-VsGD"
   },
   "source": [
    "Permutations of the following hyperparameters have been used\n",
    "\n",
    "1. Learning rates - 0.01, 0.003, 0.001, 0.0003, 0.0001\n",
    "2. Epochs 50, 100, 150, 200, 250, 400, 500, 1000\n",
    "3. Minibatch Sizes - 16, 32, 64, 128, 256, 512, 1024, 2048\n",
    "\n",
    "Learning rates 0.01 and 0.003 were not good after a certain epochs the loss wouldn't change.\n",
    "\n",
    "Best Learning rates were 0.0003 and 0.0001. So I decided to choose 0.0002\n",
    "\n",
    "Minibatch sizes greater than 64 didn't help much either. So I played around with sizes 16, 32 and 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svMPItlhVsCl"
   },
   "source": [
    "### Tests which had a good output\n",
    "I've saved their output in the folders with the same name. e.g test1\n",
    "https://drive.google.com/drive/folders/1bf0W4hnLWqzZttlmQEus1Fi5DAuthFcU?usp=sharing\n",
    "\n",
    "According to me Test 6 is the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Lt8MkQZVcp5"
   },
   "source": [
    "#### Test 1\n",
    "1. Number of Epochs - 100\n",
    "2. Minibatch size - 16\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3zmZrT1YXip"
   },
   "source": [
    "#### Test 2\n",
    "1. Number of Epochs - 500\n",
    "2. Minibatch size - 32\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koxiXD1uYZUm"
   },
   "source": [
    "#### Test 3\n",
    "1. Number of Epochs - 1000\n",
    "2. Minibatch size - 64\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yiVs-a0DmAl5"
   },
   "source": [
    "#### Test 4\n",
    "1. Number of Epochs - 1000\n",
    "2. Minibatch size - 16\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45vR1nSEqz_x"
   },
   "source": [
    "#### Test 5\n",
    "1. Number of Epochs - 500\n",
    "2. Minibatch size - 16\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-yHHnMPtHxJ"
   },
   "source": [
    "#### Test 6\n",
    "1. Number of Epochs - 200\n",
    "2. Minibatch size - 16\n",
    "3. Learning Rate - 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vGraUktyZcLe"
   },
   "source": [
    "### Observations\n",
    "Appending Silent frames before training did not help as we were using 19 random frames to predict something so I decided to add them after training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "79BvfacFZpBD"
   },
   "source": [
    "### Assumptions\n",
    "\n",
    "If Zero Padding was allowed it would've helped as the corners and edges would get equal importances as the middle elements"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw2_p2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
