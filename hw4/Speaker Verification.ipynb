{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow.keras.backend as K\n",
    "import librosa\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16180)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_trs.pkl', 'rb') as pickle_file:\n",
    "    train_data = pickle.load(pickle_file)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 22631)\n"
     ]
    }
   ],
   "source": [
    "with open('hw4_tes.pkl', 'rb') as pickle_file:\n",
    "    test_data = pickle.load(pickle_file)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Positive Pairs\n",
    "Generates all combinations of pairs and randomly selects L pairs from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pos_pairs(speaker, L=45):\n",
    "    batch = []\n",
    "    all_pairs = list(combinations(range(10), 2))\n",
    "    l_pairs = random.sample(all_pairs, L)\n",
    "    for a,b in l_pairs:\n",
    "        stft_1 = np.abs(librosa.stft(speaker[a], n_fft=1024, hop_length=512)).T\n",
    "        stft_2 = np.abs(librosa.stft(speaker[b], n_fft=1024, hop_length=512)).T\n",
    "        batch.append([stft_1, stft_2])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Negative Pairs\n",
    "The Main Speaker's utternaces lie between start and end. The other 49 speakers' utterances like before start and after end.  \n",
    "Randomly sample L utterances from the main speaker's utterances with replacement as L is greater than the number of utterances by the main speaker, i.e., L>10.  \n",
    "Whereas, we randomly sample L utterances from the other 49 speakers' utterances without replacement as L is less than their total utterances L<490.\n",
    "Using the samples from the above 2 steps we create Negative Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neg_pairs(pos_sp_num, train_data, L=45):\n",
    "    batch = []\n",
    "    \n",
    "    start = pos_sp_num*10\n",
    "    end = start + 10     \n",
    "    pos_spk = train_data[start: end]\n",
    "    neg_spk = train_data[:start] + train_data[end:]\n",
    "    neg_sample = random.sample(neg_spk, L)\n",
    "        \n",
    "    for l in range(L):\n",
    "        pos = random.choice(pos_spk)\n",
    "        \n",
    "        stft_pos = np.abs(librosa.stft(pos, n_fft=1024, hop_length=512)).T\n",
    "        stft_neg = np.abs(librosa.stft(neg_sample[l], n_fft=1024, hop_length=512)).T\n",
    "        batch.append([stft_pos, stft_neg])\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training Pairs\n",
    "Creates 2250 pairs of negative and positive examples each, i.e, 4500 total pairs.\n",
    "Final Dimensions - Pairs (4500) x Number of Inputs (2) x Shape of Spectrogram (45x513) x number of channels (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches = []\n",
    "train_data = list(train_data)\n",
    "for i in range(50):\n",
    "    pos_batch = create_pos_pairs(train_data[i:i+10])\n",
    "    neg_batch = create_neg_pairs(i, train_data)\n",
    "    mini_batches += pos_batch + neg_batch\n",
    "#     mini_batches.append(mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_np = np.stack(mini_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 2, 32, 513)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2, 45, 513)\n"
     ]
    }
   ],
   "source": [
    "mini_np = np.pad(mini_np, ((0,0), (0,0), (0, 13), (0,0)), mode = 'constant', constant_values = 0) \n",
    "print(mini_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_np_exp = np.expand_dims(mini_np, axis = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 2, 45, 513, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_np_exp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create True Predictions based on the negative/positive pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [] \n",
    "for i in range(50):\n",
    "    y = np.zeros(90, dtype = int)\n",
    "    y[:45] += 1\n",
    "    Y.append(y)\n",
    "Y = np.hstack(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Testing Pairs\n",
    "Creates 900 pairs of negative and positive examples each, i.e, 1800 total pairs.  \n",
    "Final Dimensions - Pairs (1800) x Number of Inputs (2) x Shape of Spectrogram (45x513) x number of channels (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_batches_test = []\n",
    "test_data = list(test_data)\n",
    "for i in range(20):\n",
    "    pos_batch = create_pos_pairs(test_data[i:i+10])\n",
    "    neg_batch = create_neg_pairs(i, test_data)\n",
    "    mini_batches_test += pos_batch + neg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_np_test = np.stack(mini_batches_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 2, 45, 513)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_np_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 2, 45, 513, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_np_exp_test = np.expand_dims(mini_np_test, axis = 4)\n",
    "mini_np_exp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "Binary Cross Entropy aka Sigmoid Cross Entropy is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return tf.reduce_sum(tf.losses.sigmoid_cross_entropy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function copied from [1]\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(input_shape):\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Base Network\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Conv2D(32, kernel_size = (5, 5), input_shape = input_shape, activation = 'relu'))\n",
    "    base_model.add(MaxPool2D())\n",
    "    base_model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    base_model.add(MaxPool2D())\n",
    "    base_model.add(Flatten())\n",
    "    base_model.add(Dense(1000, activation = 'tanh'))\n",
    "    \n",
    "    left_output = base_model(left_input)\n",
    "    right_output = base_model(right_input)\n",
    "    \n",
    "    print(K.shape(left_output))\n",
    "    print(K.shape(right_output))\n",
    "    \n",
    "    prediction = tf.reduce_sum(tf.multiply(left_output, right_output), axis = 1)\n",
    "    prediction = tf.reshape(prediction, [-1, 1])\n",
    "    \n",
    "#     prediction = sigmoid(K.dot(left_output, K.transpose(right_output)))\n",
    "    print(K.shape(prediction))\n",
    "    \n",
    "    siamese_model = Model(inputs = [left_input, right_input], outputs = prediction)\n",
    "    \n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Shape_3:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"Shape_4:0\", shape=(2,), dtype=int32)\n",
      "Tensor(\"Shape_5:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "model = siamese_model([45, 513, 1])\n",
    "model.compile(loss=loss, optimizer = tf.keras.optimizers.Adam(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 45, 513, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 45, 513, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1000)         72596328    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, 1000)]       0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None,)]            0           tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 1)]          0           tf_op_layer_Sum_1[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 72,596,328\n",
      "Trainable params: 72,596,328\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 1800 samples\n",
      "Epoch 1/50\n",
      "4500/4500 [==============================] - 107s 24ms/sample - loss: 10.4775 - binary_accuracy: 0.5111 - val_loss: 0.6940 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "4480/4500 [============================>.] - ETA: 0s - loss: 0.6923 - binary_accuracy: 0.5009"
     ]
    }
   ],
   "source": [
    "model.fit([mini_np_exp[:, 0], mini_np_exp[:, 1]], Y, batch_size=32, epochs=50, validation_data=([mini_np_exp_test[:, 0], mini_np_exp_test[:, 1]] ,Y[:1800]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. https://keras.io/examples/mnist_siamese/\n",
    "2. https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0\n",
    "3. https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
    "4. https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('siamese.cpkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
