{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speaker Verification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu5HQxe_vMoh",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVMyaKTbfnDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import random\n",
        "from itertools import combinations, product\n",
        "\n",
        "import pickle\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzE96aTfzUy5",
        "colab_type": "text"
      },
      "source": [
        "### Load Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z2pod13fyLL",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "618d6511-ead4-45e4-8a91-3fe2b11bc3e5"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2cd64e5-5f0e-47e8-b5f4-e6142ad27b4a\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c2cd64e5-5f0e-47e8-b5f4-e6142ad27b4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hw4_tes.pkl to hw4_tes.pkl\n",
            "Saving hw4_trs.pkl to hw4_trs.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKiP2vAsf2cC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48ff1990-2f23-4c84-df7f-1fbc8d187001"
      },
      "source": [
        "with open('hw4_trs.pkl', 'rb') as pickle_file:\n",
        "    train_data = pickle.load(pickle_file)\n",
        "print(train_data.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 16180)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERjzc8ZPf-iL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8e9b0f1-fdf9-4d33-9104-c7bcfcf14438"
      },
      "source": [
        "with open('hw4_tes.pkl', 'rb') as pickle_file:\n",
        "    test_data = pickle.load(pickle_file)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 22631)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V879fkbMgAEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in train_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcgCEbpogBs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = np.stack([np.abs(librosa.stft(x, n_fft=1024, hop_length=512).T) for x in test_data])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFTMlToTzfsq",
        "colab_type": "text"
      },
      "source": [
        "### Create Positive Pairs\n",
        "Generates all 45 combinations of pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5czByMgES8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pos_pairs(spk_indices, L=45):\n",
        "    pos_pairs = list(combinations(spk_indices, 2))\n",
        "    return pos_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibb4uF9Yznsf",
        "colab_type": "text"
      },
      "source": [
        "### Create Negative Pairs\n",
        "A = indices of positive speaker's utterances  \n",
        "B = Indices of other speakers' utterances  \n",
        "Take the cartesian product of A and B and sample 45 pairs from it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y67ez_HOgHT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_neg_pairs(spk_indices, other_indices, L=45):\n",
        "    neg_pairs = list(product(spk_indices, other_indices))\n",
        "    l_pairs = random.sample(neg_pairs, L)\n",
        "    return l_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99jtQAPTzv04",
        "colab_type": "text"
      },
      "source": [
        "### Create Training and Testing Batches\n",
        "Creates 50 batches for Training and 20 Batches for Testing. Each batch has 45 pairs of negative examples and 45 pairs of positive examples, i.e, 90 total pairs in each batch.\n",
        "\n",
        "Final Dimensions of Training Data - Batches(50) x Pairs (90) x Transposed Shape of Spectrogram (32x513)\n",
        "\n",
        "Final Dimensions of Testing Data - Batches(20) x Pairs (90) x Transposed Shape of Spectrogram (45x513)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTLwWbcTgHxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batches(data):\n",
        "    total_utterances = data.shape[0]\n",
        "    all_indices = list(range(total_utterances))\n",
        "    \n",
        "    left_input = []\n",
        "    right_input = []\n",
        "    output = []\n",
        "    \n",
        "    for i in range(0, total_utterances, 10):\n",
        "        speaker_indices = list(range(i, i+10))\n",
        "        pos_pairs = create_pos_pairs(speaker_indices)\n",
        "        other_indices = np.delete(all_indices, speaker_indices)\n",
        "        neg_pairs = create_neg_pairs(speaker_indices, other_indices)\n",
        "        \n",
        "        l_batch = []\n",
        "        r_batch = []\n",
        "        o_batch = []\n",
        "\n",
        "        for x, y in pos_pairs:\n",
        "            l_batch.append(data[x])\n",
        "            r_batch.append(data[y])\n",
        "            o_batch.append(1)\n",
        "\n",
        "        for x, y in neg_pairs:\n",
        "            l_batch.append(data[x])\n",
        "            r_batch.append(data[y])\n",
        "            o_batch.append(0)\n",
        "        \n",
        "        left_input.append(l_batch)\n",
        "        right_input.append(r_batch)\n",
        "        output.append(o_batch)\n",
        "    \n",
        "    return np.stack(left_input), np.stack(right_input), np.stack(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_g6fERgJMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "left_train, right_train, y_train = generate_batches(train_data)\n",
        "left_test, right_test, y_test = generate_batches(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijlyy17ihvzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6634a280-437d-471b-dc87-7e0dd85355b6"
      },
      "source": [
        "print(left_train.shape, left_train.dtype)\n",
        "print(right_train.shape, right_train.dtype)\n",
        "print(y_train.shape,y_train.dtype)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 90, 32, 513) float32\n",
            "(50, 90, 32, 513) float32\n",
            "(50, 90) int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhafvU0ghxPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6f7d328f-565c-4a76-ad04-d8a7f1ef9b76"
      },
      "source": [
        "print(left_test.shape, left_test.dtype)\n",
        "print(right_test.shape, right_test.dtype)\n",
        "print(y_test.shape,y_test.dtype)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 90, 45, 513) float32\n",
            "(20, 90, 45, 513) float32\n",
            "(20, 90) int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5PDDMTNz5nf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faa896c8-93bc-43a8-d600-772d0374d3c8"
      },
      "source": [
        " y_train = y_train.astype(np.float32)\n",
        " print(y_train.dtype)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yozc_D-zhs2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d0a4359-1a43-45df-e5fa-2ebceb801cc7"
      },
      "source": [
        " y_test = y_test.astype(np.float32)\n",
        " print(y_test.dtype)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_d-K41Kz1IK",
        "colab_type": "text"
      },
      "source": [
        "### Create Placeholders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nURvCb3hyml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders():\n",
        "  left_x = tf.placeholder(tf.float32,shape = [None,None,513])\n",
        "  right_x = tf.placeholder(tf.float32,shape = [None,None,513])\n",
        "  y = tf.placeholder(tf.float32,shape = [None])\n",
        "  rows = tf.placeholder(tf.int32)\n",
        "\n",
        "  return left_x, right_x, y, rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFv4yA8Ez31-",
        "colab_type": "text"
      },
      "source": [
        "### Defines the Base of the Siamese Model\n",
        "Uses an LSTM Layer followed by a Dense Layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4_-fqBk1Crc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def siamese_model(inputs, reuse, rows, num_units = [513]):\n",
        "  cells = [tf.contrib.rnn.BasicLSTMCell(num_units=n, reuse = reuse) for n in num_units]\n",
        "  stacked_lstm = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
        "  rnn_op, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, dtype = tf.float32)\n",
        "  dense_1 = tf.layers.dense(rnn_op, 513, activation=tf.nn.tanh, reuse = reuse)\n",
        "  output = tf.reshape(dense_1,shape = [-1, rows*513])\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM98k0lJz7jw",
        "colab_type": "text"
      },
      "source": [
        "### Define Complete Model\n",
        "Total Number of Epochs =  100\n",
        "Learning rate =  0.0005\n",
        "Optimizer = Adam  \n",
        "Loss Funtion = Sigmoid Cross Entropy  \n",
        "Cost is the mean of all the losses for each prediction  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vMiNf17uO7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(train_data, test_data, learning_rate = 0.0005, num_epochs = 100):\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "  x1, x2, y, rows  = create_placeholders()\n",
        "  left_train, right_train, y_train = train_data\n",
        "  left_test, right_test, y_test = test_data\n",
        "\n",
        "  left_op = siamese_model(x1,False,rows)\n",
        "  right_op = siamese_model(x2,True,rows)\n",
        "  dot_prod = tf.reduce_sum(tf.multiply(left_op,right_op),axis = 1)\n",
        "  yPred = tf.nn.sigmoid(dot_prod)\n",
        "\n",
        "  binary_op = tf.cast(tf.math.greater(yPred,0.5), tf.int16)\n",
        "  \n",
        "  cost = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = dot_prod))\n",
        "  \n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "  init = tf.global_variables_initializer()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0\n",
        "        i = 0\n",
        "        for left, right, y_batch in zip(left_train,right_train,y_train):\n",
        "          row = left.shape[1]\n",
        "\n",
        "          _, batch_loss = sess.run([optimizer, cost], feed_dict ={x1: left, x2: right, y:y_batch, rows:row })  \n",
        "          epoch_loss += batch_loss\n",
        "          i += 1\n",
        "        \n",
        "        test_accuracy = 0.0\n",
        "        j = 0\n",
        "        for left,right,y_batch in zip(left_test,right_test,y_test):\n",
        "            row = left.shape[1]\n",
        "            y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
        "            test_accuracy += sum(y_pred == y_batch)\n",
        "            j+=1\n",
        "\n",
        "        print(epoch,\"Cost:\", epoch_loss/i, \" Test Accuracy: \", test_accuracy/j)\n",
        "\n",
        "    test_accuracy = 0.0\n",
        "    j = 0\n",
        "    for left,right,y_batch in zip(left_test,right_test,y_test):\n",
        "      row = left.shape[1]\n",
        "      y_pred = sess.run(binary_op, feed_dict ={x1: left, x2: right, y:y_batch, rows: row})\n",
        "      test_accuracy += sum(y_pred == y_batch)\n",
        "      j+=1\n",
        "    \n",
        "    print(\"Final Test Accuracy: \", test_accuracy/j)\n",
        "    return test_accuracy/j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg9qDES60DPO",
        "colab_type": "text"
      },
      "source": [
        "### Training\n",
        "Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoO9Pi2QuSmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3633dc1f-c023-4f8f-cf17-479f6a87e3f3"
      },
      "source": [
        "tr_data = [left_train, right_train, y_train.astype(float)]\n",
        "te_data = [left_test, right_test, y_test]\n",
        "acc = model(tr_data, te_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-17-db0bcce9b542>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-17-db0bcce9b542>:3: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-17-db0bcce9b542>:4: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-17-db0bcce9b542>:5: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "0 Cost: 479.0689714050293  Test Accuracy:  59.1\n",
            "1 Cost: 59.04717826843262  Test Accuracy:  62.15\n",
            "2 Cost: 47.900637817382815  Test Accuracy:  62.7\n",
            "3 Cost: 43.49810768127441  Test Accuracy:  62.75\n",
            "4 Cost: 40.11901588439942  Test Accuracy:  62.65\n",
            "5 Cost: 36.78536388397217  Test Accuracy:  62.7\n",
            "6 Cost: 33.08686038970947  Test Accuracy:  61.5\n",
            "7 Cost: 28.606659030914308  Test Accuracy:  60.85\n",
            "8 Cost: 23.814946632385254  Test Accuracy:  60.35\n",
            "9 Cost: 19.2204607963562  Test Accuracy:  59.95\n",
            "10 Cost: 15.025126900672912  Test Accuracy:  60.55\n",
            "11 Cost: 11.992812724113465  Test Accuracy:  60.6\n",
            "12 Cost: 13.24472116947174  Test Accuracy:  57.5\n",
            "13 Cost: 14.910587482452392  Test Accuracy:  58.95\n",
            "14 Cost: 13.86307367324829  Test Accuracy:  56.4\n",
            "15 Cost: 9.81391531944275  Test Accuracy:  57.6\n",
            "16 Cost: 6.525692777633667  Test Accuracy:  58.0\n",
            "17 Cost: 7.607980947494507  Test Accuracy:  56.85\n",
            "18 Cost: 6.594970504045486  Test Accuracy:  58.3\n",
            "19 Cost: 3.715991487503052  Test Accuracy:  59.0\n",
            "20 Cost: 5.623070752620697  Test Accuracy:  58.6\n",
            "21 Cost: 5.217183154225349  Test Accuracy:  58.8\n",
            "22 Cost: 4.091306466460228  Test Accuracy:  56.3\n",
            "23 Cost: 2.9277741330862046  Test Accuracy:  59.3\n",
            "24 Cost: 4.746783950328827  Test Accuracy:  56.4\n",
            "25 Cost: 3.6178668415546418  Test Accuracy:  56.75\n",
            "26 Cost: 3.211835196018219  Test Accuracy:  58.6\n",
            "27 Cost: 2.876199359297752  Test Accuracy:  58.4\n",
            "28 Cost: 3.0020923814177514  Test Accuracy:  58.0\n",
            "29 Cost: 1.4375704488158225  Test Accuracy:  60.0\n",
            "30 Cost: 1.199328692704439  Test Accuracy:  61.75\n",
            "31 Cost: 0.4285625943168998  Test Accuracy:  63.1\n",
            "32 Cost: 0.39228649854660036  Test Accuracy:  60.85\n",
            "33 Cost: 3.957503710240126  Test Accuracy:  55.5\n",
            "34 Cost: 34.04901154994965  Test Accuracy:  53.55\n",
            "35 Cost: 17.977932305335997  Test Accuracy:  61.1\n",
            "36 Cost: 5.135995458066463  Test Accuracy:  58.7\n",
            "37 Cost: 2.413551999479532  Test Accuracy:  59.75\n",
            "38 Cost: 0.8305471481382847  Test Accuracy:  62.5\n",
            "39 Cost: 0.2747259445441887  Test Accuracy:  61.4\n",
            "40 Cost: 0.11806941966991871  Test Accuracy:  61.8\n",
            "41 Cost: 0.0864330821740441  Test Accuracy:  61.9\n",
            "42 Cost: 0.06925451504532248  Test Accuracy:  61.7\n",
            "43 Cost: 0.057375093260779976  Test Accuracy:  61.7\n",
            "44 Cost: 0.048629635450197384  Test Accuracy:  61.75\n",
            "45 Cost: 0.041922100700903686  Test Accuracy:  61.85\n",
            "46 Cost: 0.03662309061968699  Test Accuracy:  62.0\n",
            "47 Cost: 0.03233968004933559  Test Accuracy:  62.0\n",
            "48 Cost: 0.028812641187105328  Test Accuracy:  62.3\n",
            "49 Cost: 0.025863693212158978  Test Accuracy:  62.3\n",
            "50 Cost: 0.023366120923892595  Test Accuracy:  62.25\n",
            "51 Cost: 0.02122737625672016  Test Accuracy:  62.3\n",
            "52 Cost: 0.019378322754055263  Test Accuracy:  62.35\n",
            "53 Cost: 0.017766286792466418  Test Accuracy:  62.3\n",
            "54 Cost: 0.01635047060903162  Test Accuracy:  62.35\n",
            "55 Cost: 0.015098789832554757  Test Accuracy:  62.35\n",
            "56 Cost: 0.01398569272365421  Test Accuracy:  62.5\n",
            "57 Cost: 0.012990571927512065  Test Accuracy:  62.5\n",
            "58 Cost: 0.01209664753288962  Test Accuracy:  62.45\n",
            "59 Cost: 0.011290125080558938  Test Accuracy:  62.45\n",
            "60 Cost: 0.010559555708896369  Test Accuracy:  62.5\n",
            "61 Cost: 0.009895364986732602  Test Accuracy:  62.55\n",
            "62 Cost: 0.009289497887948528  Test Accuracy:  62.55\n",
            "63 Cost: 0.008735116729803849  Test Accuracy:  62.6\n",
            "64 Cost: 0.008226391013886314  Test Accuracy:  62.6\n",
            "65 Cost: 0.007758320410794113  Test Accuracy:  62.55\n",
            "66 Cost: 0.0073265914898365736  Test Accuracy:  62.55\n",
            "67 Cost: 0.006927462749299593  Test Accuracy:  62.5\n",
            "68 Cost: 0.006557677128294017  Test Accuracy:  62.45\n",
            "69 Cost: 0.006214388796361163  Test Accuracy:  62.45\n",
            "70 Cost: 0.0058950922224903475  Test Accuracy:  62.4\n",
            "71 Cost: 0.00559758648276329  Test Accuracy:  62.45\n",
            "72 Cost: 0.005319915116706398  Test Accuracy:  62.45\n",
            "73 Cost: 0.005060348371043802  Test Accuracy:  62.45\n",
            "74 Cost: 0.004817350209923461  Test Accuracy:  62.45\n",
            "75 Cost: 0.004589536890562158  Test Accuracy:  62.5\n",
            "76 Cost: 0.00437567454035161  Test Accuracy:  62.5\n",
            "77 Cost: 0.004174658301635646  Test Accuracy:  62.55\n",
            "78 Cost: 0.003985489144251914  Test Accuracy:  62.55\n",
            "79 Cost: 0.0038072621688479556  Test Accuracy:  62.55\n",
            "80 Cost: 0.003639164670894388  Test Accuracy:  62.55\n",
            "81 Cost: 0.003480459709680872  Test Accuracy:  62.55\n",
            "82 Cost: 0.0033304723468609155  Test Accuracy:  62.45\n",
            "83 Cost: 0.0031885900427005252  Test Accuracy:  62.5\n",
            "84 Cost: 0.0030542574291757773  Test Accuracy:  62.55\n",
            "85 Cost: 0.0029269620809645857  Test Accuracy:  62.55\n",
            "86 Cost: 0.0028062366363883484  Test Accuracy:  62.6\n",
            "87 Cost: 0.002691653633955866  Test Accuracy:  62.65\n",
            "88 Cost: 0.0025828176793584135  Test Accuracy:  62.65\n",
            "89 Cost: 0.00247936573199695  Test Accuracy:  62.65\n",
            "90 Cost: 0.002380964125331957  Test Accuracy:  62.65\n",
            "91 Cost: 0.0022873056496609933  Test Accuracy:  62.65\n",
            "92 Cost: 0.002198105377610773  Test Accuracy:  62.65\n",
            "93 Cost: 0.002113097919500433  Test Accuracy:  62.65\n",
            "94 Cost: 0.002032038307515904  Test Accuracy:  62.65\n",
            "95 Cost: 0.001954700956994202  Test Accuracy:  62.6\n",
            "96 Cost: 0.0018808730169257615  Test Accuracy:  62.6\n",
            "97 Cost: 0.0018103606330987531  Test Accuracy:  62.6\n",
            "98 Cost: 0.0017429781434475445  Test Accuracy:  62.6\n",
            "99 Cost: 0.0016785576019901782  Test Accuracy:  62.55\n",
            "Final Test Accuracy:  62.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc4n55G30M2l",
        "colab_type": "text"
      },
      "source": [
        "### Final Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_xbWdObuVXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c476e97b-2e7a-45de-b8b8-e73a29473e00"
      },
      "source": [
        "print(\"Test Accuracy = \", acc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy =  62.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fylqd1ym09w4",
        "colab_type": "text"
      },
      "source": [
        "### Things I tried\n",
        "Models - \n",
        "1. Stacking Convolution Layers and using Euclidean Distance between embeddings\n",
        "2. Stacking GRUs\n",
        "3. ConvLSTM2D\n",
        "4. BinaryCrossEntropy Loss and Contrasive Loss\n",
        "\n",
        "Used to get stuck at Test accuracy at 50% using the above models which were built using keras. I think the model wasn't reusing the weights so I built a new Siamese model just LSTM without keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de-84D2dEeMP",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "1. https://keras.io/examples/mnist_siamese/\n",
        "2. https://medium.com/predict/face-recognition-from-scratch-using-siamese-networks-and-tensorflow-df03e32f8cd0\n",
        "3. https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18\n",
        "4. https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emNg1WJrEdK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXocFt_zuzUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}